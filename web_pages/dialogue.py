import os
from datetime import datetime
from io import BytesIO

import streamlit as st
from streamlit_chatbox import *
from audio_recorder_streamlit import audio_recorder
from utils.config_utils import header, prompt_data, call_with_messages, call_with_stream
from utils.exec_cmd import execute_command

chat_box = ChatBox(
    assistant_avatar=os.path.join(
        "img",
        "chatchat_icon_blue_square_v2.png"
    )
)

# å¯¹è¯ä¸»ç•Œé¢é€»è¾‘
def dialogue_page():
    # åˆ›å»ºå¯¹è¯åŒºåŸŸå’Œè¾“å…¥åŒºåŸŸ
    st.title(header)

    greeting()

    chat_input_placeholder = "è¯·è¾“å…¥å¯¹è¯å†…å®¹ï¼Œæ¢è¡Œè¯·ä½¿ç”¨Shift+Enterã€‚"
    # å½“ç”¨æˆ·æäº¤é—®é¢˜æ—¶çš„é€»è¾‘
    if user_input := st.chat_input(chat_input_placeholder, key="prompt"):
        answer_by_steps(user_input)

    extra_btn()


# æ¬¢è¿æç¤ºæ¡†
def greeting():
    if call_with_messages.__module__ == "agent.glm_agent":
        model_name = "è¡Œè‡³å†›äº‹å¤§æ¨¡å‹"
    elif call_with_messages.__module__ == "agent.qwen_agent":
        model_name = "è¡Œè‡³å†›äº‹å¤§æ¨¡å‹"
    else:
        model_name = "è¡Œè‡³å†›äº‹å¤§æ¨¡å‹"
    if not chat_box.chat_inited:
        st.toast(
            f"æ¬¢è¿ä½¿ç”¨{header}! \n\n"
            f"å½“å‰è¿è¡Œçš„æ¨¡å‹`{model_name}`, æ‚¨å¯ä»¥å¼€å§‹ä½¿ç”¨äº†."
        )
        chat_box.init_session()
    chat_box.output_messages()


# åˆ†æ­¥å›ç­”
def answer_by_steps(user_input):
    chat_box.reset_history()
    chat_box.user_say(user_input)
    prompt_list = prompt_data.copy()
    length = len(prompt_list)
    if length == 0:
        message = "æ²¡æœ‰å¯¹åº”æç¤ºè¯ï¼Œè¯·ç¡®è®¤åé‡è¯•"
        chat_box.update_msg(message, streaming=False)
        return
    if length > 1:
        chain_of_thought(prompt_list, user_input)
    else:
        only_one = prompt_list.pop(-1)
        full_content = ''
        for r in call_with_stream(only_one["prompt"].format(question=user_input)):
            full_content += r
            chat_box.update_msg(full_content, streaming=True)
        chat_box.update_msg(full_content, streaming=False)
        return


# æ€ç»´é“¾
def chain_of_thought(prompt_list, user_input):
    first_prompt = prompt_list.pop(0)["prompt"]
    last_prompt = prompt_list.pop(-1)["prompt"]
    execution_failed = False
    all_messages = init_all_steps()
    chat_box.ai_say(all_messages)
    results = []
    # ç¬¬ä¸€æ¬¡è°ƒç”¨
    execution_failed = first_step(execution_failed, first_prompt, user_input, results)

    # ä¸­é—´è¿‡ç¨‹
    execution_failed = intermediate_steps(execution_failed, prompt_list, user_input, results)

    # æœ€åä¸€æ¬¡æµå¼å›ç­”
    final_step(execution_failed, last_prompt, user_input, results)


def compose_prompt(origin_prompt, user_input, results):
    actual_prompt = origin_prompt
    if "{question}" in origin_prompt:
        actual_prompt = origin_prompt.replace("{question}", user_input)
    for index, result in enumerate(results):
        if f"{{result{index + 1}}}" in actual_prompt:
            actual_prompt = actual_prompt.replace(f"{{result{index + 1}}}", result)
    return actual_prompt


def first_step(execution_failed, first_prompt, user_input, results):
    try:
        result = call_with_messages(first_prompt.format(question=user_input))

        chat_box.update_msg(result, expanded=True, element_index=0, streaming=False, state="complete")
        chat_box.update_msg("è¿›è¡Œä¸­...", element_index=1, streaming=False, expanded=True)
        print(f"-----------ç¬¬1æ¬¡ç»“æœ:\n{result}")
        print("------------ç¬¬ä¸€æ¬¡ç»“æŸ\n")
        results.append(result)
    except Exception as e:
        print(e)
        chat_box.update_msg('<font color="red">ç½‘ç»œå¼‚å¸¸ï¼Œè¯·é‡è¯•</font>', element_index=0, streaming=False, state="error")
        execution_failed = True
    return execution_failed


def intermediate_steps(execution_failed, prompt_list, user_input, results):
    if execution_failed:
        for index in range(len(prompt_list)):
            chat_box.update_msg('<font color="red">å‰åºæ­¥éª¤å‡ºé”™ï¼Œæš‚åœæ‰§è¡Œ</font>', element_index=index + 1,
                                streaming=False, expanded=True, state="error")
    else:
        for index, content in enumerate(prompt_list):
            try:
                actual_prompt = compose_prompt(content["prompt"], user_input, results)

                result = call_with_messages(actual_prompt)

                chat_box.update_msg(element_index=index, expanded=False)
                chat_box.update_msg(result, element_index=index + 1, streaming=False, expanded=True, state="complete")
                chat_box.update_msg("è¿›è¡Œä¸­...", element_index=index + 2, streaming=False, expanded=True)
                print(f"-----------ç¬¬{index + 2}æ¬¡ç»“æœ:\n{result}")
                print(f"------------ç¬¬{index + 2}æ¬¡ç»“æŸ\n")
                results.append(result)
            except Exception as e:
                print(e)
                chat_box.update_msg('<font color="red">ç½‘ç»œå¼‚å¸¸ï¼Œè¯·é‡è¯•</font>', element_index=index + 1,
                                    streaming=False, state="error")
                execution_failed = True

    return execution_failed


def final_step(execution_failed, last_prompt, user_input, results):
    if execution_failed:
        chat_box.update_msg('<font color="red">å‰åºæ­¥éª¤å‡ºé”™ï¼Œæš‚åœæ‰§è¡Œ</font>', element_index=-1, streaming=False,
                            expanded=True, state="error")
    else:
        full_content = ''  # with incrementally we need to merge output.
        try:
            for r in call_with_stream(compose_prompt(last_prompt, user_input, results)):
                full_content += r
                chat_box.update_msg(full_content, element_index=-1, streaming=True, expanded=True)
            chat_box.update_msg(element_index=-2, expanded=False)
            chat_box.update_msg(full_content, element_index=-1, streaming=False, state="complete")
            print(f"-----------æœ€åä¸€æ¬¡ç»“æœ:\n{full_content}")
            print("-----------æœ€åä¸€æ¬¡ç»“æŸ\n")
            if execute_command(full_content):
                st.toast("æ‰§è¡ŒæˆåŠŸ", icon='ğŸ‰')
            else:
                st.toast("ç½‘ç»œæ³¢åŠ¨ï¼Œè¯·é‡è¯•", icon='ğŸ›œ')
        except Exception as e:
            print(e)
            chat_box.update_msg(full_content + '<br/><br/><font color="red">ç½‘ç»œå¼‚å¸¸ï¼Œè¯·é‡è¯•</font>', element_index=-1,
                                streaming=False, state="error")


def init_all_steps():
    all_messages = [Markdown("è¿›è¡Œä¸­", in_expander=True, expanded=False, title=prompt_data[0]["title"])]
    for i in range(1, len(prompt_data)):
        all_messages.append(Markdown("ç­‰å¾…ä¸­...", in_expander=True,
                                     expanded=False, title=prompt_data[i]["title"]))
    return all_messages


# é¢å¤–æŒ‰é’®ï¼ˆåŒ…æ‹¬æ–°å»ºå¯¹è¯ä¸å¯¼å‡ºè®°å½•ï¼‰
def extra_btn():
    now = datetime.now()
    with st.sidebar:
        new_btn = st.container()
        export_btn = st.container()
        # æ–°å»ºå¯¹è¯ï¼ˆåˆ é™¤å†å²è®°å½•ï¼Œåˆ·æ–°é¡µé¢ï¼‰
        if new_btn.button(
                ":speech_balloon: æ–°å»ºå¯¹è¯",
                use_container_width=True,
        ):
            chat_box.reset_history()
            st.rerun()

    # å¯¼å‡ºè®°å½•ï¼ˆä¸‹è½½chat_boxå¯¼å‡ºçš„markdownå†…å®¹ï¼‰
    export_btn.download_button(
        ":file_folder: å¯¼å‡ºè®°å½•",
        "".join(chat_box.export2md()),
        file_name=f"{now:%Y-%m-%d %H.%M}_å¯¹è¯è®°å½•.md",
        mime="text/markdown",
        use_container_width=True,
    )
